#!/usr/bin/env python3
import time
from substrateinterface import SubstrateInterface, Keypair
import rospy
#import ipfshttpclient as ipfs
import json

from ipfs_common.ipfs_rosbag import IpfsRosBag
from ipfs_common.msg import Multihash
from helpers.models import Liability as L
from helpers import ipfs
from helpers.models import Base, engine, db_session
from helpers.robonomics_model import RobonomicsModel as RM

class DatalogCacher:

    def __init__(self):

        rospy.init_node("datalog_listener")
        rospy.loginfo("Launching datalog cacher node...")
        # # Database
        # Base.metadata.create_all(engine)
        # self.session = db_session()
        rospy.loginfo("Datalog cacher node is launched!")

        Base.metadata.create_all(engine)
        self.session = db_session()

        try:
            self.substrate = SubstrateInterface(
                url=rospy.get_param("/liability_cacher/datalog_cacher/endpoint"),
                ss58_format=42,
                type_registry={
                    'types': {
                        "Record": "Vec<u8>",
                        "TechnicalParam": "Vec<u8>",
                        "TechnicalReport": "Vec<u8>",
                        "EconomicalParam": "{}",
                        "ProofParam": "MultiSignature",
                        "LiabilityIndex": "u64",
                        "BlockLength": "(u32,u32,u32)"
                    }
                }
            )
        except ConnectionRefusedError:
            print("⚠️ No local Substrate node running, try running 'start_local_substrate_node.sh' first")
            exit()

        self.agents = [
            "4GzMLepDF5nKTWDM6XpB3CrBcFmwgazcVFAD3ZBNAjKT6hQJ"
        ]

        self.agent_public_keys = [

        ]

        self.model = "QmRHLgQVJK9r9ioQHzNXgSFBvYwceWMm5EQeKUJrvR8jUW"
        self.validator = "0x0000000000000000000000000000000000000000"
        self.validatorFee = "0"
        self.token = "0x668B3a6F9b6C4a2759Fa3912D0a59f39d1F0f0B0"
        self.model_data = ipfs.ipfs_download(self.model)
        # print(self.model_data)

    def datalog_listener(self):

        for a in self.agents:
            kp = Keypair(ss58_address=a)
            self.agent_public_keys.append({'type': 'AccountId', 'value': kp.public_key})

        print(f"Public keys: {self.agent_public_keys}")

        while True:
            ch = self.substrate.get_chain_head()
            print(f"Chain head: {ch}")

            events = self.substrate.get_events(ch)
            for e in events:
                if e.value["event_id"] == "NewRecord":
                    print(f'new record {e}')
                    #print(e.params)
                    if any(x in e.params for x in self.agent_public_keys):
                        for p in e.params:
                            if p["type"] == "Record":
                                print(p["value"])
                                self.ipfs_hash = p["value"]
                                self.update_cacher()

            time.sleep(1.5)

    def update_cacher(self):
        rm = RM(self.model)
        print(f'rm {rm.objective(Multihash(self.ipfs_hash))}')
        data = rm.objective(Multihash(self.ipfs_hash))
        updated_data = L(
                address         = self.agents[0],
                model           = self.model,
                model_data      = self.model_data,
                objective       = str(self.ipfs_hash),
                objective_data  = data,
                promisee        = self.agents[0],
                promisor        = self.agents[0],
                lighthouse      = "0xD40AC7F1e5401e03D00F5aeC1779D8e5Af4CF9f1",
                token           = self.token,
                cost            = 100,
                result          = self.ipfs_hash,
                result_data     = data,
                validator       = self.validator,
                validatorFee    = self.validatorFee
        )
        rospy.loginfo(f"updated_data {updated_data}")

        try:
            self.session.add(updated_data)
            self.session.commit()
            rospy.loginfo(updated_data)

        except Exception as e:
            self.session.rollback()
            rospy.logerr("Didn't commit datalog data: {}".format(e))
    


if __name__ == "__main__":
    DatalogCacher().datalog_listener()
